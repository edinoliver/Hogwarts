{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVdPqXtcgWrAuy2nbRWdLJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edinoliver/Hogwarts/blob/main/Harry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hogwards - The school for learning"
      ],
      "metadata": {
        "id": "erdIOZsPUQZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# MINI-DUOLINGO A1‚ÄìB1 (Colab)\n",
        "# Palavras: Oxford 3000 (A1‚ÄìB1)\n",
        "# Frases: ManyThings/Tatoeba EN-PT, filtradas para usar SOMENTE palavras Oxford A1‚ÄìB1\n",
        "# =========================\n",
        "\n",
        "!pip -q install PyPDF2\n",
        "import os, subprocess, zipfile, re, unicodedata, random\n",
        "import pandas as pd\n",
        "from PyPDF2 import PdfReader\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# -------------------------\n",
        "# 0) Fun√ß√µes utilit√°rias\n",
        "# -------------------------\n",
        "def normalize_text(s: str) -> str:\n",
        "    s = str(s).strip().lower()\n",
        "    s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')  # remove acentos\n",
        "    s = re.sub(r\"[^\\w\\s']\", \" \", s)  # mant√©m ap√≥strofo\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def similarity(a: str, b: str) -> float:\n",
        "    return SequenceMatcher(None, normalize_text(a), normalize_text(b)).ratio()\n",
        "\n",
        "def is_correct(user_answer: str, accepted_answers, threshold=0.86):\n",
        "    best_ans, best_sc = \"\", 0.0\n",
        "    for ans in accepted_answers:\n",
        "        sc = similarity(user_answer, ans)\n",
        "        if sc > best_sc:\n",
        "            best_ans, best_sc = ans, sc\n",
        "    return (best_sc >= threshold), best_ans, best_sc\n",
        "\n",
        "def tokenize_en(s: str):\n",
        "    # tokens alfab√©ticos + ap√≥strofo interno (don't)\n",
        "    s = normalize_text(s)\n",
        "    return re.findall(r\"[a-z]+(?:'[a-z]+)?\", s)\n",
        "\n",
        "# -------------------------\n",
        "# 1) Baixar Oxford 3000 por CEFR (com fallback)\n",
        "# Fonte oficial do PDF (Oxford Learner's Dictionaries) [1](https://langeek.co/en/vocab/level-based)\n",
        "# Alternativa .co.uk [5](https://www.esl-lounge.com/student/word-bank.php)\n",
        "# Espelho GitHub [6](https://englishintake.com/learn-english/vocabulary/)\n",
        "# -------------------------\n",
        "targets = [\n",
        "  \"https://www.oxfordlearnersdictionaries.com/external/pdf/wordlists/oxford-3000-5000/The_Oxford_3000_by_CEFR_level.pdf\",   # [1](https://langeek.co/en/vocab/level-based)\n",
        "  \"https://www.oxfordlearnersdictionaries.co.uk/us/external/pdf/wordlists/oxford-3000-5000/The_Oxford_3000_by_CEFR_level.pdf\", # [5](https://www.esl-lounge.com/student/word-bank.php)\n",
        "  \"https://raw.githubusercontent.com/XA2005/CEFR-World-List/main/The_Oxford_3000_by_CEFR_level.pdf\", # [6](https://englishintake.com/learn-english/vocabulary/)\n",
        "]\n",
        "ua = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\"\n",
        "pdf_path = \"oxford_3000_cefr.pdf\"\n",
        "\n",
        "def wget(url, out):\n",
        "    cmd = [\"wget\", \"-O\", out, url, \"--user-agent\", ua, \"--tries=10\", \"--waitretry=3\", \"--timeout=20\", \"--retry-connrefused\"]\n",
        "    r = subprocess.run(cmd, capture_output=True, text=True)\n",
        "    return r.returncode, r.stderr\n",
        "\n",
        "if os.path.exists(pdf_path):\n",
        "    os.remove(pdf_path)\n",
        "\n",
        "ok = False\n",
        "for url in targets:\n",
        "    code, err = wget(url, pdf_path)\n",
        "    if os.path.exists(pdf_path) and os.path.getsize(pdf_path) > 50_000:\n",
        "        ok = True\n",
        "        break\n",
        "\n",
        "if not ok:\n",
        "    raise RuntimeError(\"N√£o consegui baixar o PDF. Fa√ßa upload manual com o nome 'oxford_3000_cefr.pdf' na aba Files e rode de novo.\")\n",
        "\n",
        "print(\"‚úÖ PDF Oxford 3000 baixado:\", pdf_path, f\"({os.path.getsize(pdf_path)/1024:.1f} KB)\")\n",
        "\n",
        "# -------------------------\n",
        "# 2) Extrair palavras A1‚ÄìB1 do Oxford 3000 por n√≠vel\n",
        "# (O PDF √© 'Oxford 3000 by CEFR level') [1](https://langeek.co/en/vocab/level-based)\n",
        "# -------------------------\n",
        "LEVELS = [\"A1\", \"A2\", \"B1\", \"B2\"]\n",
        "\n",
        "def extract_pages_text(pdf_path: str):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    return [(p.extract_text() or \"\") for p in reader.pages]\n",
        "\n",
        "def parse_oxford_words_by_level(pages_text):\n",
        "    text = \"\\n\".join(pages_text).replace(\"\\xa0\", \" \")\n",
        "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
        "\n",
        "    found = []\n",
        "    for lv in LEVELS:\n",
        "        m = re.search(rf\"\\b{lv}\\b\", text)\n",
        "        if m:\n",
        "            found.append((lv, m.start()))\n",
        "    found.sort(key=lambda x: x[1])\n",
        "    if len(found) < 2:\n",
        "        return {}\n",
        "\n",
        "    blocks = {}\n",
        "    for i, (lv, start) in enumerate(found):\n",
        "        end = found[i+1][1] if i+1 < len(found) else len(text)\n",
        "        blocks[lv] = text[start:end]\n",
        "\n",
        "    pos_pattern = r\"\\b(adj|adv|aux|conj|det|modal|n|num|prep|pron|v)\\.?\\b\"\n",
        "\n",
        "    def extract_items(block: str):\n",
        "        b = re.sub(pos_pattern, \" \", block, flags=re.I)\n",
        "        b = re.sub(r\"\\b\\d+\\b\", \" \", b)\n",
        "        b = re.sub(r\"\\s+\", \" \", b).strip()\n",
        "\n",
        "        # tokens simples; depois filtramos com regras\n",
        "        tokens = re.findall(r\"[A-Za-z][A-Za-z'\\-]*\", b)\n",
        "        out, seen = [], set()\n",
        "        for t in tokens:\n",
        "            w = t.lower()\n",
        "            if len(w) >= 2 and w not in seen:\n",
        "                seen.add(w)\n",
        "                out.append(w)\n",
        "        return out\n",
        "\n",
        "    return {lv: extract_items(bl) for lv, bl in blocks.items()}\n",
        "\n",
        "pages = extract_pages_text(pdf_path)\n",
        "words_by_level = parse_oxford_words_by_level(pages)\n",
        "\n",
        "A1_words = words_by_level.get(\"A1\", [])\n",
        "A2_words = words_by_level.get(\"A2\", [])\n",
        "B1_words = words_by_level.get(\"B1\", [])\n",
        "\n",
        "# Banco final (A1‚ÄìB1)\n",
        "bank_A1_B1 = list(dict.fromkeys(A1_words + A2_words + B1_words))\n",
        "\n",
        "# Conjunto para filtragem de frases: apenas palavras \"a-z\" e com ap√≥strofo\n",
        "oxford_set = set([w for w in bank_A1_B1 if re.fullmatch(r\"[a-z]+(?:'[a-z]+)?\", w)])\n",
        "\n",
        "print(\"‚úÖ Banco Oxford A1‚ÄìB1 pronto:\", len(oxford_set), \"palavras (aprox.)\")\n",
        "\n",
        "# -------------------------\n",
        "# 3) Baixar e preparar frases EN-PT (ManyThings/Tatoeba)\n",
        "# ManyThings/Anki fornece pares tab-delimited (derivados do Tatoeba) [2](https://github.com/XA2005/CEFR-World-List/blob/main/The_Oxford_3000_by_CEFR_level.pdf)\n",
        "# Tatoeba tamb√©m disponibiliza downloads oficiais [3](https://www.oxfordlearnersdictionaries.com/external/pdf/wordlists/oxford-3000-5000/The_Oxford_3000_by_CEFR_level.pdf)\n",
        "# -------------------------\n",
        "zip_name = \"por-eng.zip\"\n",
        "if not os.path.exists(zip_name):\n",
        "    !wget -O por-eng.zip \"https://www.manythings.org/anki/por-eng.zip\"\n",
        "print(\"‚úÖ ZIP de frases baixado:\", zip_name)\n",
        "\n",
        "# extrair\n",
        "extract_dir = \"tatoeba_por_eng\"\n",
        "if not os.path.exists(extract_dir):\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_name, 'r') as z:\n",
        "        z.extractall(extract_dir)\n",
        "\n",
        "txt_files = [f for f in os.listdir(extract_dir) if f.endswith(\".txt\")]\n",
        "if not txt_files:\n",
        "    raise RuntimeError(\"N√£o encontrei arquivo .txt dentro do zip por-eng.zip\")\n",
        "pairs_path = os.path.join(extract_dir, txt_files[0])\n",
        "\n",
        "# carregar dataset (formato t√≠pico: id \\t en \\t pt)\n",
        "df = pd.read_csv(pairs_path, sep=\"\\t\", header=None, names=[\"id\", \"en\", \"pt\"], quoting=3)\n",
        "df = df.dropna(subset=[\"en\", \"pt\"])\n",
        "print(\"‚úÖ Pares carregados:\", len(df))\n",
        "\n",
        "# -------------------------\n",
        "# 4) Filtrar frases para A1‚ÄìB1:\n",
        "# Regras:\n",
        "#  - ingl√™s e pt com 3..12 palavras (ajust√°vel)\n",
        "#  - ingl√™s cont√©m SOMENTE palavras do Oxford A1‚ÄìB1 (tokeniza√ß√£o simples)\n",
        "#  - remove frases com caracteres estranhos\n",
        "# -------------------------\n",
        "MIN_WORDS = 3\n",
        "MAX_WORDS = 12\n",
        "\n",
        "def word_count_simple(s):\n",
        "    return len(re.findall(r\"[A-Za-z√Ä-√ø']+\", str(s)))\n",
        "\n",
        "def looks_ok_en(s):\n",
        "    s = str(s)\n",
        "    # bloqueia s√≠mbolos ‚Äúestranhos‚Äù que aparecem em legendas/c√≥digos\n",
        "    if re.search(r\"[_#@/\\\\\\[\\]{}<>]\", s):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def only_oxford_words(en_sentence):\n",
        "    toks = tokenize_en(en_sentence)\n",
        "    if not toks:\n",
        "        return False\n",
        "    return all(t in oxford_set for t in toks)\n",
        "\n",
        "# limpeza leve\n",
        "df[\"en\"] = df[\"en\"].astype(str).str.strip()\n",
        "df[\"pt\"] = df[\"pt\"].astype(str).str.strip()\n",
        "\n",
        "filtered = df[\n",
        "    df[\"en\"].apply(looks_ok_en) &\n",
        "    df[\"en\"].apply(word_count_simple).between(MIN_WORDS, MAX_WORDS) &\n",
        "    df[\"pt\"].apply(word_count_simple).between(MIN_WORDS, MAX_WORDS) &\n",
        "    df[\"en\"].apply(only_oxford_words)\n",
        "].copy()\n",
        "\n",
        "filtered = filtered.drop_duplicates(subset=[\"en\", \"pt\"])\n",
        "print(\"‚úÖ Frases filtradas (somente Oxford A1‚ÄìB1):\", len(filtered))\n",
        "\n",
        "if len(filtered) < 50:\n",
        "    print(\"‚ö†Ô∏è Ficou pouca frase. Voc√™ pode relaxar o filtro aumentando MAX_WORDS ou diminuindo exig√™ncia.\")\n",
        "else:\n",
        "    print(\"Exemplos:\")\n",
        "    print(filtered.sample(5, random_state=42)[[\"en\",\"pt\"]].to_string(index=False))\n",
        "\n",
        "# -------------------------\n",
        "# 5) TESTE: 10 palavras + 10 frases rand√¥micas filtradas\n",
        "# Palavras: autoavalia√ß√£o (Oxford n√£o traz tradu√ß√£o PT) [1](https://langeek.co/en/vocab/level-based)\n",
        "# Frases: corre√ß√£o autom√°tica com similaridade (EN->PT do corpus) [2](https://github.com/XA2005/CEFR-World-List/blob/main/The_Oxford_3000_by_CEFR_level.pdf)\n",
        "# -------------------------\n",
        "def run_test(word_bank, sentences_df, n_words=10, n_sentences=10, seed=None, threshold=0.86):\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "\n",
        "    chosen_words = random.sample(list(word_bank), k=min(n_words, len(word_bank)))\n",
        "    chosen_rows = sentences_df.sample(n=min(n_sentences, len(sentences_df)), random_state=seed)\n",
        "    chosen_sentences = list(zip(chosen_rows[\"en\"].tolist(), chosen_rows[\"pt\"].tolist()))\n",
        "\n",
        "    total = len(chosen_words) + len(chosen_sentences)\n",
        "    correct = 0\n",
        "\n",
        "    print(\"\\nüü¶ TESTE A1‚ÄìB1 ‚Äî 10 palavras + 10 frases (RAND√îMICAS e filtradas)\")\n",
        "    print(\"‚Ä¢ Palavras: Oxford 3000 A1‚ÄìB1 (por CEFR).\")  # [1](https://langeek.co/en/vocab/level-based)\n",
        "    print(\"‚Ä¢ Frases: ManyThings/Tatoeba EN‚ÄìPT filtradas para usar apenas vocabul√°rio Oxford A1‚ÄìB1.\")  # [2](https://github.com/XA2005/CEFR-World-List/blob/main/The_Oxford_3000_by_CEFR_level.pdf)\n",
        "    print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\\n\")\n",
        "\n",
        "    # Palavras (autoavalia√ß√£o)\n",
        "    print(\"üü© Parte 1 ‚Äî Palavras (autoavalia√ß√£o)\\n\")\n",
        "    for i, w in enumerate(chosen_words, 1):\n",
        "        _ = input(f\"{i:02d}) Traduza a palavra: '{w}' ‚Üí \")\n",
        "        s = input(\"   Voc√™ considera que acertou? (s/n) ‚Üí \").strip().lower()\n",
        "        if s.startswith(\"s\"):\n",
        "            correct += 1\n",
        "            print(\"   ‚úÖ Marcado como correto.\\n\")\n",
        "        else:\n",
        "            print(\"   ‚ùå Marcado como incorreto.\\n\")\n",
        "\n",
        "    # Frases (corre√ß√£o autom√°tica)\n",
        "    print(\"\\nüü® Parte 2 ‚Äî Frases (rand√¥micas, apenas vocabul√°rio A1‚ÄìB1)\\n\")\n",
        "    base = len(chosen_words)\n",
        "    for j, (en, pt) in enumerate(chosen_sentences, 1):\n",
        "        user = input(f\"{base + j:02d}) Traduza: \\\"{en}\\\" ‚Üí \")\n",
        "        ok, best, sc = is_correct(user, [pt], threshold=threshold)\n",
        "        if ok:\n",
        "            correct += 1\n",
        "            print(f\"   ‚úÖ Correto! (similaridade {sc:.2f})\\n\")\n",
        "        else:\n",
        "            print(f\"   ‚ùå Gabarito: {pt} (sua similaridade: {sc:.2f})\\n\")\n",
        "\n",
        "    grade = (correct / total) * 10 if total else 0.0\n",
        "    print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
        "    print(f\"üìå Acertos: {correct}/{total}\")\n",
        "    print(f\"üèÅ Nota final: {grade:.1f} / 10\")\n",
        "    print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
        "    print(\"\\nüîñ Atribui√ß√£o: Senten√ßas derivadas do Tatoeba (licen√ßa CC BY).\")  # [3](https://www.oxfordlearnersdictionaries.com/external/pdf/wordlists/oxford-3000-5000/The_Oxford_3000_by_CEFR_level.pdf)[4](https://anyflip.com/fnsg/tvbr/basic)\n"
      ],
      "metadata": {
        "id": "40FMamsbUXOR",
        "outputId": "91718a90-e1a6-40b3-ff22-92deb9dd4276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ PDF Oxford 3000 baixado: oxford_3000_cefr.pdf (113.7 KB)\n",
            "‚úÖ Banco Oxford A1‚ÄìB1 pronto: 2980 palavras (aprox.)\n",
            "--2026-02-24 11:03:45--  https://www.manythings.org/anki/por-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6633028 (6.3M) [application/zip]\n",
            "Saving to: ‚Äòpor-eng.zip‚Äô\n",
            "\n",
            "por-eng.zip         100%[===================>]   6.33M  9.13MB/s    in 0.7s    \n",
            "\n",
            "2026-02-24 11:03:47 (9.13 MB/s) - ‚Äòpor-eng.zip‚Äô saved [6633028/6633028]\n",
            "\n",
            "‚úÖ ZIP de frases baixado: por-eng.zip\n",
            "‚úÖ Pares carregados: 0\n",
            "‚úÖ Frases filtradas (somente Oxford A1‚ÄìB1): 0\n",
            "‚ö†Ô∏è Ficou pouca frase. Voc√™ pode relaxar o filtro aumentando MAX_WORDS ou diminuindo exig√™ncia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Executar o teste\n",
        "run_test(oxford_set, filtered, n_words=10, n_sentences=10, threshold=0.86, seed=None)"
      ],
      "metadata": {
        "id": "hyJsNCZPUZte",
        "outputId": "0a6389ca-41bc-45f9-e0e1-c9462eddab8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üü¶ TESTE A1‚ÄìB1 ‚Äî 10 palavras + 10 frases (RAND√îMICAS e filtradas)\n",
            "‚Ä¢ Palavras: Oxford 3000 A1‚ÄìB1 (por CEFR).\n",
            "‚Ä¢ Frases: ManyThings/Tatoeba EN‚ÄìPT filtradas para usar apenas vocabul√°rio Oxford A1‚ÄìB1.\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
            "\n",
            "üü© Parte 1 ‚Äî Palavras (autoavalia√ß√£o)\n",
            "\n",
            "01) Traduza a palavra: 'ski' ‚Üí Esqui\n",
            "   Voc√™ considera que acertou? (s/n) ‚Üí s\n",
            "   ‚úÖ Marcado como correto.\n",
            "\n",
            "02) Traduza a palavra: 'scary' ‚Üí Assustado\n",
            "   Voc√™ considera que acertou? (s/n) ‚Üí s\n",
            "   ‚úÖ Marcado como correto.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-787865522.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Executar o teste\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moxford_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.86\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1262606306.py\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m(word_bank, sentences_df, n_words, n_sentences, seed, threshold)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üü© Parte 1 ‚Äî Palavras (autoavalia√ß√£o)\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{i:02d}) Traduza a palavra: '{w}' ‚Üí \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"   Voc√™ considera que acertou? (s/n) ‚Üí \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}